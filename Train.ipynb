{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaphBhz/Scenarformer/blob/main/Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkq4GeSc4NrJ"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6jwOn_f4Jx-",
        "outputId": "9c3e611e-5026-4266-a85d-53145db58a9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBbDQsRD4G-k"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z0zelyR33274"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import random\n",
        "import torch\n",
        "import os.path\n",
        "from requests.exceptions import HTTPError\n",
        "\n",
        "DATA_PATH = F\"/content/gdrive/MyDrive/AI/Scenarformer/plays/\"\n",
        "\n",
        "def load_play_text(path):\n",
        "  with open(path) as file:\n",
        "    data = file.read()\n",
        "    return data\n",
        "\n",
        "\n",
        "def get_batch(play_files, batch_size, block_size, episode, steps_num):\n",
        "  num_plays = len(play_files)\n",
        "  # Select a play based on episode index\n",
        "  play_idx = episode % num_plays\n",
        "  play_text = load_play_text(play_files[play_idx])\n",
        "\n",
        "  # Convert the play text to tokens\n",
        "  tokens = torch.tensor(enc.encode(play_text), dtype=torch.long)\n",
        "\n",
        "  # We want to get a specific number of batches for this episode\n",
        "  for _ in range(steps_num):\n",
        "      # Generate random starting indices for the batch\n",
        "      start_idx = torch.randint(len(tokens) - block_size, (batch_size,))\n",
        "      inputs = torch.stack([tokens[i:i+block_size] for i in start_idx])\n",
        "      outputs = torch.stack([tokens[i+1:i+block_size+1] for i in start_idx])\n",
        "      yield inputs, outputs\n",
        "\n",
        "\n",
        "def split_files(play_dir = DATA_PATH, validation_ratio=0.1):\n",
        "  # Get all .txt files in the directory\n",
        "  all_files = [os.path.join(root, file)\n",
        "                for root, _, files in os.walk(play_dir)\n",
        "                for file in files if file.endswith('.txt')]\n",
        "\n",
        "  # Shuffle the files\n",
        "  random.shuffle(all_files)\n",
        "\n",
        "  # Calculate the split index\n",
        "  split_idx = int(len(all_files) * (1 - validation_ratio))\n",
        "\n",
        "  # Split into training and validation\n",
        "  train_files = all_files[:split_idx]\n",
        "  val_files = all_files[split_idx:]\n",
        "\n",
        "  return train_files, val_files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nP70LqVE4oOS"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WYkiUUwM4kTM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class SelfAttentionHead(nn.Module):\n",
        "  def __init__(self, head_size, embedding_size, block_size, dropout):\n",
        "    super().__init__()\n",
        "    self.key = nn.Linear(embedding_size, head_size, bias = False)\n",
        "    self.query = nn.Linear(embedding_size, head_size, bias = False)\n",
        "    self.value = nn.Linear(embedding_size, head_size, bias = False)\n",
        "    self.droupout = nn.Dropout(dropout)\n",
        "    self.register_buffer('mask', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "  def forward(self, x):\n",
        "    Batch, Block, Size = x.shape\n",
        "\n",
        "    keys = self.key(x)\n",
        "    queries = self.query(x)\n",
        "\n",
        "    weights = queries @ keys.transpose(-2, -1) * Size ** -0.5\n",
        "    weights = weights.masked_fill(self.mask[:Block, :Block] == 0, float('-inf'))\n",
        "    weights = nn.functional.softmax(weights, dim=-1)\n",
        "    weights = self.droupout(weights)\n",
        "\n",
        "    values = self.value(x)\n",
        "\n",
        "    return weights @ values\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self, head_size, num_heads, embedding_size, block_size, dropout):\n",
        "    super().__init__()\n",
        "    self.heads = nn.ModuleList(\n",
        "      [SelfAttentionHead(head_size, embedding_size, block_size, dropout) for _ in range(num_heads)]\n",
        "    )\n",
        "    self.projection = nn.Linear(embedding_size, embedding_size)\n",
        "    self.droupout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "    y = self.projection(y)\n",
        "    y = self.droupout(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "class FeedForwardLayer(nn.Module):\n",
        "  def __init__(self, embedding_size, dropout):\n",
        "    super().__init__()\n",
        "    self.network = nn.Sequential(\n",
        "      nn.Linear(embedding_size, 4 * embedding_size),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(4 * embedding_size, embedding_size),\n",
        "      nn.Dropout(dropout)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.network(x)\n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "  def __init__(self, embedding_size, block_size, num_heads, dropout = 0.2):\n",
        "    super().__init__()\n",
        "    head_size = embedding_size // num_heads\n",
        "    self.attention_heads = MultiHeadAttention(head_size, num_heads, embedding_size, block_size, dropout)\n",
        "    self.feedforward_layer = FeedForwardLayer(embedding_size, dropout)\n",
        "    self.layer_norm1 = nn.LayerNorm(embedding_size)\n",
        "    self.layer_norm2 = nn.LayerNorm(embedding_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x + self.attention_heads(x)\n",
        "    x = x + self.feedforward_layer(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_size, block_size, layer_num=6, attention_heads=8, dropout=0.2):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, embedding_size)\n",
        "    self.position_embedding_table = nn.Embedding(block_size, embedding_size)\n",
        "    self.decoder_blocks = nn.Sequential(\n",
        "      *[DecoderBlock(embedding_size, block_size, num_heads=attention_heads, dropout=dropout) for _ in range(layer_num)],\n",
        "      nn.LayerNorm(embedding_size)\n",
        "    )\n",
        "    self.linear_layer = nn.Linear(embedding_size, vocab_size)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    Batch, Block = idx.shape\n",
        "\n",
        "    token_embeddings = self.token_embedding_table(idx)\n",
        "    positional_embeddings = self.position_embedding_table(torch.arange(Block))\n",
        "\n",
        "    embeddings = token_embeddings + positional_embeddings\n",
        "    embeddings = self.decoder_blocks(embeddings)\n",
        "\n",
        "    logits = self.linear_layer(embeddings)\n",
        "\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      Batch, Block, Vocab = logits.shape\n",
        "      logits = logits.view(Batch * Block, Vocab)\n",
        "      targets = targets.view(Batch * Block)\n",
        "      loss = nn.functional.cross_entropy(logits, targets)\n",
        "\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max):\n",
        "    Batch, Block = idx.shape\n",
        "\n",
        "    for _ in range(max):\n",
        "      cropped_idx = idx[:, -Block:]\n",
        "      logits, loss = self(cropped_idx)\n",
        "      logits = logits [:,-1,:]\n",
        "      probs = nn.functional.softmax(logits, dim=-1)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d9yoPup4rjV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-vH_QaD46b7"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WUkRlWIL45yS"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import tiktoken\n",
        "import torch\n",
        "import os.path\n",
        "\n",
        "# Making sure the model uses GPU\n",
        "torch.set_default_device('cuda')\n",
        "\n",
        "# Part of data used for validation\n",
        "VALIDATION_RATIO = 0.1\n",
        "\n",
        "# Number of sequences to train at a time\n",
        "BATCH_SIZE = 64\n",
        "# Size of each sequence\n",
        "BLOCK_SIZE = 128\n",
        "# Size of embeddings\n",
        "EMBEDDING_SIZE = 512\n",
        "# Number of episodes to train for\n",
        "TRAIN_EPISODES = 50\n",
        "# Number of steps in each episode\n",
        "TRAIN_STEPS = 500\n",
        "# Number of steps in the validation\n",
        "VALIDATION_STEPS = 100\n",
        "# Learning rate\n",
        "LEARNING_RATE = 1e-5\n",
        "\n",
        "# Using tiktoken's r50k_base encoder\n",
        "enc = tiktoken.get_encoding(\"r50k_base\")\n",
        "\n",
        "# Path to save the model to\n",
        "def MODEL_PATH(episode, date = None):\n",
        "  model_name = f'model_{datetime.today().strftime(\"%Y-%m-%d\") if date is None else date}_{episode}.pth'\n",
        "  return f\"/content/gdrive/MyDrive/AI/Scenarformer/{model_name}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPTXKY-J8B-L",
        "outputId": "c2c60163-4cfb-4e92-be9f-e6f42b747fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into test and validation sets\n",
        "train_files, validation_files = split_files()\n",
        "print(f'Number of training plays: {len(train_files)}')\n",
        "print(f'Number of validation plays: {len(validation_files)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Svsvk4caz0xS",
        "outputId": "293f7f97-60db-42f4-e1bf-1c600fc4bce3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training plays: 45\n",
            "Number of validation plays: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1wCdgVT6G8q",
        "outputId": "01aa64f4-5f03-49cb-f21f-b03485152b8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPISODE 1\n",
            "Loss = 9.0617 Validation Loss = 8.9995\n",
            "EPISODE 2\n",
            "Loss = 7.9674 Validation Loss = 7.8777\n",
            "EPISODE 3\n",
            "Loss = 7.3190 Validation Loss = 7.2179\n",
            "EPISODE 4\n",
            "Loss = 6.7164 Validation Loss = 6.6344\n",
            "EPISODE 5\n",
            "Loss = 6.3308 Validation Loss = 6.2557\n",
            "EPISODE 6\n",
            "Loss = 5.8787 Validation Loss = 5.7774\n",
            "EPISODE 7\n",
            "Loss = 5.4076 Validation Loss = 5.3613\n",
            "EPISODE 8\n",
            "Loss = 5.5083 Validation Loss = 5.4260\n",
            "EPISODE 9\n",
            "Loss = 5.4192 Validation Loss = 5.3126\n",
            "EPISODE 10\n",
            "Loss = 5.1549 Validation Loss = 5.0661\n",
            "EPISODE 11\n",
            "Loss = 4.8744 Validation Loss = 4.7751\n",
            "EPISODE 12\n",
            "Loss = 4.6056 Validation Loss = 4.5894\n",
            "EPISODE 13\n",
            "Loss = 4.6929 Validation Loss = 4.5980\n",
            "EPISODE 14\n",
            "Loss = 4.8088 Validation Loss = 4.7587\n",
            "EPISODE 15\n",
            "Loss = 4.5545 Validation Loss = 4.5095\n",
            "EPISODE 16\n",
            "Loss = 4.3269 Validation Loss = 4.2734\n",
            "EPISODE 17\n",
            "Loss = 4.2190 Validation Loss = 4.1745\n",
            "EPISODE 18\n",
            "Loss = 4.1713 Validation Loss = 4.0179\n",
            "EPISODE 19\n",
            "Loss = 4.4696 Validation Loss = 4.4143\n",
            "EPISODE 20\n",
            "Loss = 4.2520 Validation Loss = 4.1769\n",
            "EPISODE 21\n",
            "Loss = 4.0648 Validation Loss = 3.9590\n",
            "EPISODE 22\n",
            "Loss = 3.9919 Validation Loss = 3.8993\n",
            "EPISODE 23\n",
            "Loss = 3.6406 Validation Loss = 3.5474\n",
            "EPISODE 24\n",
            "Loss = 4.2549 Validation Loss = 4.1690\n",
            "EPISODE 25\n",
            "Loss = 4.0177 Validation Loss = 3.9397\n",
            "EPISODE 26\n",
            "Loss = 3.7898 Validation Loss = 3.7363\n",
            "EPISODE 27\n",
            "Loss = 3.7427 Validation Loss = 3.7185\n",
            "EPISODE 28\n",
            "Loss = 3.3499 Validation Loss = 3.1791\n",
            "EPISODE 29\n",
            "Loss = 4.0818 Validation Loss = 3.9928\n",
            "EPISODE 30\n",
            "Loss = 3.8681 Validation Loss = 3.7792\n",
            "EPISODE 31\n",
            "Loss = 3.6541 Validation Loss = 3.5713\n",
            "EPISODE 32\n",
            "Loss = 3.6257 Validation Loss = 3.5822\n",
            "EPISODE 33\n",
            "Loss = 3.0154 Validation Loss = 2.8799\n",
            "EPISODE 34\n",
            "Loss = 3.8991 Validation Loss = 3.8587\n",
            "EPISODE 35\n",
            "Loss = 3.7540 Validation Loss = 3.6544\n",
            "EPISODE 36\n",
            "Loss = 3.5230 Validation Loss = 3.4385\n",
            "EPISODE 37\n",
            "Loss = 3.5451 Validation Loss = 3.4829\n",
            "EPISODE 38\n",
            "Loss = 2.8044 Validation Loss = 2.6217\n",
            "EPISODE 39\n",
            "Loss = 3.8659 Validation Loss = 3.7491\n",
            "EPISODE 40\n",
            "Loss = 3.5808 Validation Loss = 3.5535\n",
            "EPISODE 41\n",
            "Loss = 3.3451 Validation Loss = 3.3348\n",
            "EPISODE 42\n",
            "Loss = 3.5403 Validation Loss = 3.4024\n",
            "EPISODE 43\n",
            "Loss = 2.5612 Validation Loss = 2.4068\n",
            "EPISODE 44\n",
            "Loss = 3.7294 Validation Loss = 3.6549\n",
            "EPISODE 45\n",
            "Loss = 3.5423 Validation Loss = 3.4776\n",
            "EPISODE 46\n",
            "Loss = 3.2861 Validation Loss = 3.2315\n",
            "EPISODE 47\n",
            "Loss = 3.3704 Validation Loss = 3.3351\n",
            "EPISODE 48\n",
            "Loss = 2.3900 Validation Loss = 2.2200\n",
            "EPISODE 49\n",
            "Loss = 3.7161 Validation Loss = 3.5758\n",
            "EPISODE 50\n",
            "Loss = 3.4611 Validation Loss = 3.4086\n",
            "! abcher...\n",
            "Elle puis cdue votre échafvalier tes neord, je ne pas Sortelque a rigue eût-je don tranquil-lu qui me mes sentiments ?\n",
            "Mais de me réclément tout per...cessleraime, c'Ét lesains, j'enir.\n",
            "Oui à m'a perdu : reconnais-vous, c'une faire n'est mon soin de vous autre de en conform et grontison.\n",
            "Ô change ; je vous n'elle n'avez,isherressez ces de lQue cette Alto... Céule sacryr surpriseit appro soldant, quels, sais à billet lauf ! Vous le tra l'est un chère, et lesurs ne connaître à vous qu'ilà être est tant d'il en moins pourrieve j'est de la grâ rav faire, où jee, vous ! Dpe j'occCar Solar m'indre l'il dise je vous bien jette croire de vot mystrêtre et doule l'estiez vous ta l'en est le m'aille se muset dans et...\n",
            "Mon le cul le confusion.210 détement n'est qu'y ax une secret des joiez-vous ?\n",
            "Mont passion,z-urer la galis d'estéprouclair, mon amour.\n",
            "Je ne sochés à vous chares donc veux ? Mais pour cat de téton auir à ; je crain votre a que tu son peux dont il le ré leptinuis et je fera être et l'aura ! Sanse les déese !... Au peut-jeite. Il l'est déj'est O, Mademoiselle j'est pas le jamais déconorage : éché ! Noni-vous ?\n",
            "St est trop avis me qu'en douquet n' burdensirper aussi...\n",
            "quez pourai quumière ; vous l'ils quelifie les distquet... eût dire... Mais... Un d'aviez. Mais\n"
          ]
        }
      ],
      "source": [
        "from torch.amp import autocast, GradScaler\n",
        "\n",
        "# Creating the model\n",
        "m = SimpleModel(\n",
        "  vocab_size=enc.n_vocab,\n",
        "  embedding_size=EMBEDDING_SIZE,\n",
        "  block_size = BLOCK_SIZE\n",
        ")\n",
        "m.cuda()\n",
        "\n",
        "# Using torch's Adam optimizer\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=LEARNING_RATE)\n",
        "# Using a ReduceLROnPlateau scheduler\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=4, cooldown=1)\n",
        "\n",
        "# Initialize GradScaler for scaling gradients\n",
        "scaler = GradScaler('cuda')\n",
        "\n",
        "# Training the model\n",
        "for episode in range(TRAIN_EPISODES):\n",
        "  print(f'EPISODE {episode+1}')\n",
        "  m.train()\n",
        "\n",
        "  batches = get_batch(validation_files, BATCH_SIZE, BLOCK_SIZE, episode, VALIDATION_STEPS)\n",
        "  for inp, out in batches:\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "    with autocast('cuda'):\n",
        "      logits, loss = m(inp, out)\n",
        "\n",
        "    # Scale the loss and backpropagate\n",
        "    scaler.scale(loss).backward()\n",
        "    scaler.step(optimizer)\n",
        "    scaler.update()\n",
        "\n",
        "  # Validation\n",
        "  m.eval()\n",
        "  validation_loss = 0\n",
        "  with torch.no_grad():\n",
        "    batches = get_batch(validation_files, BATCH_SIZE, BLOCK_SIZE, episode, VALIDATION_STEPS)\n",
        "    for val_inp, val_out in batches:\n",
        "      with autocast('cuda'):\n",
        "        val_logits, val_loss = m(val_inp, val_out)\n",
        "      validation_loss += val_loss.item()\n",
        "\n",
        "    # Compute average validation loss\n",
        "    validation_loss /= VALIDATION_STEPS\n",
        "\n",
        "  # Step the scheduler\n",
        "  scheduler.step(validation_loss)\n",
        "\n",
        "  # Save model\n",
        "  if (episode + 1) % 10 == 0:\n",
        "    torch.save(m.state_dict(), MODEL_PATH(episode+1))\n",
        "\n",
        "  print(f'Loss = {loss.item():.4f} Validation Loss = {validation_loss:.4f}')\n",
        "\n",
        "\n",
        "# Printing a sample of generation\n",
        "print(enc.decode(m.generate(torch.zeros((1, 1), dtype=torch.long), 500)[0].tolist()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNzZfIFfCSG6"
      },
      "source": [
        "# Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ANzgxMWlABCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a8d7d6-c182-4d28-99a2-7713ef9fe0db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleModel(\n",
              "  (token_embedding_table): Embedding(50257, 512)\n",
              "  (position_embedding_table): Embedding(128, 512)\n",
              "  (decoder_blocks): Sequential(\n",
              "    (0): DecoderBlock(\n",
              "      (attention_heads): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x SelfAttentionHead(\n",
              "            (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (droupout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (droupout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (feedforward_layer): FeedForwardLayer(\n",
              "        (network): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (1): DecoderBlock(\n",
              "      (attention_heads): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x SelfAttentionHead(\n",
              "            (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (droupout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (droupout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (feedforward_layer): FeedForwardLayer(\n",
              "        (network): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (2): DecoderBlock(\n",
              "      (attention_heads): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x SelfAttentionHead(\n",
              "            (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (droupout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (droupout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (feedforward_layer): FeedForwardLayer(\n",
              "        (network): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (3): DecoderBlock(\n",
              "      (attention_heads): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x SelfAttentionHead(\n",
              "            (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (droupout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (droupout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (feedforward_layer): FeedForwardLayer(\n",
              "        (network): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (4): DecoderBlock(\n",
              "      (attention_heads): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x SelfAttentionHead(\n",
              "            (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (droupout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (droupout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (feedforward_layer): FeedForwardLayer(\n",
              "        (network): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (5): DecoderBlock(\n",
              "      (attention_heads): MultiHeadAttention(\n",
              "        (heads): ModuleList(\n",
              "          (0-7): 8 x SelfAttentionHead(\n",
              "            (key): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (query): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (value): Linear(in_features=512, out_features=64, bias=False)\n",
              "            (droupout): Dropout(p=0.2, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (projection): Linear(in_features=512, out_features=512, bias=True)\n",
              "        (droupout): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "      (feedforward_layer): FeedForwardLayer(\n",
              "        (network): Sequential(\n",
              "          (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (1): ReLU()\n",
              "          (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (3): Dropout(p=0.2, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (6): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (linear_layer): Linear(in_features=512, out_features=50257, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "MODEL_NAME = MODEL_PATH('50', '2024-12-10')\n",
        "\n",
        "model = SimpleModel(\n",
        "  vocab_size=enc.n_vocab,\n",
        "  embedding_size=512,\n",
        "  block_size = BLOCK_SIZE\n",
        ")\n",
        "model.load_state_dict(torch.load(MODEL_NAME, weights_only=True))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AyBcmL2fC4t4"
      },
      "outputs": [],
      "source": [
        "generated_play = enc.decode(model.generate(torch.zeros((1, 1), dtype=torch.long), 5000)[0].tolist())\n",
        "\n",
        "with open(f'/content/gdrive/MyDrive/AI/Scenarformer/generated.txt', 'w') as file:\n",
        "  file.seek(0)\n",
        "  file.write(generated_play)\n",
        "  file.truncate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tN1oRGltLde-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOj2klCvR0teTvoamyBE7mH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}